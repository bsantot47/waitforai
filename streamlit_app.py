import streamlit as st
import logging
from huggingface_hub import InferenceClient
import re

# Configuration du logger
logging.basicConfig(level=logging.DEBUG)

# RÃ©cupÃ©ration de la clÃ© API Hugging Face depuis les secrets de Streamlit
api_key = st.secrets["HUGGINGFACE_API_KEY"]

# Initialisation du client Hugging Face avec la clÃ© API rÃ©cupÃ©rÃ©e
client = InferenceClient(api_key=api_key)

# Interface Streamlit
st.title("ğŸ§ Explorateur de Sous-questions avec IA")

# SÃ©lecteur de langue
languages = {
    "English": "en",
    "FranÃ§ais": "fr",
    "EspaÃ±ol": "es",
    "PortuguÃªs": "pt",
    "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©": "ar",
    "Ğ ÑƒÑÑĞºĞ¸Ğ¹": "ru",
    "à¤¹à¤¿à¤¨à¥à¤¦à¥€": "hi",
    "Deutsch": "de",
    "æ—¥æœ¬èª": "ja"
}
selected_language = st.selectbox("SÃ©lectionnez la langue", list(languages.keys()))

# Textes fixes traduits
translations = {
    "English": {
        "enter_question": "Enter a main question:",
        "initial_response": "Complete response generated:",
        "main_question": "Main question:",
        "response": "Response:",
        "your_response": "Your response to the main question:",
        "validate_response": "Validate main response",
        "sub_questions_1": "Sub-questions Level 1:",
        "sub_questions_2": "Sub-sub-questions Level 2:",
        "final_summary": "Final summary:",
        "compare_responses": "Compare responses:",
        "initial_response": "Initial response:",
        "final_response": "Final response:",
        "summary_details": "Summary details:",
        "generate_final_summary": "Generate final summary"
    },
    "FranÃ§ais": {
        "enter_question": "Entrez une question principale :",
        "initial_response": "RÃ©ponse complÃ¨te gÃ©nÃ©rÃ©e :",
        "main_question": "Question principale :",
        "response": "RÃ©ponse :",
        "your_response": "Votre rÃ©ponse Ã  la question principale :",
        "validate_response": "Valider la rÃ©ponse principale",
        "sub_questions_1": "Sous-questions de Niveau 1 :",
        "sub_questions_2": "Sous-sous-questions de Niveau 2 :",
        "final_summary": "Reformulation finale :",
        "compare_responses": "Comparaison des rÃ©ponses :",
        "initial_response": "RÃ©ponse initiale :",
        "final_response": "RÃ©ponse reformulÃ©e :",
        "summary_details": "DÃ©tails des Ã©tapes de reformulation :",
        "generate_final_summary": "GÃ©nÃ©rer la reformulation finale"
    },
    "EspaÃ±ol": {
        "enter_question": "Introduce una pregunta principal:",
        "initial_response": "Respuesta completa generada:",
        "main_question": "Pregunta principal:",
        "response": "Respuesta:",
        "your_response": "Tu respuesta a la pregunta principal:",
        "validate_response": "Validar respuesta principal",
        "sub_questions_1": "Subpreguntas de Nivel 1:",
        "sub_questions_2": "Sub-subpreguntas de Nivel 2:",
        "final_summary": "Resumen final:",
        "compare_responses": "Comparar respuestas:",
        "initial_response": "Respuesta inicial:",
        "final_response": "Respuesta reformulada:",
        "summary_details": "Detalles del resumen:",
        "generate_final_summary": "Generar resumen final"
    },
    "PortuguÃªs": {
        "enter_question": "Insira uma pergunta principal:",
        "initial_response": "Resposta completa gerada:",
        "main_question": "Pergunta principal:",
        "response": "Resposta:",
        "your_response": "Sua resposta Ã  pergunta principal:",
        "validate_response": "Validar resposta principal",
        "sub_questions_1": "Subperguntas de NÃ­vel 1:",
        "sub_questions_2": "Sub-subperguntas de NÃ­vel 2:",
        "final_summary": "Resumo final:",
        "compare_responses": "Comparar respostas:",
        "initial_response": "Resposta inicial:",
        "final_response": "Resposta reformulada:",
        "summary_details": "Detalhes do resumo:",
        "generate_final_summary": "Gerar resumo final"
    },
    "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©": {
        "enter_question": "Ø£Ø¯Ø®Ù„ Ø³Ø¤Ø§Ù„Ø§Ù‹ Ø±Ø¦ÙŠØ³ÙŠØ§Ù‹:",
        "initial_response": "Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø© Ø§Ù„Ù…ÙˆÙ„Ø¯Ø©:",
        "main_question": "Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ:",
        "response": "Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:",
        "your_response": "Ø¥Ø¬Ø§Ø¨ØªÙƒ Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ:",
        "validate_response": "ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©",
        "sub_questions_1": "Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ÙØ±Ø¹ÙŠØ© Ù…Ø³ØªÙˆÙ‰ 1:",
        "sub_questions_2": "Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ÙØ±Ø¹ÙŠØ© Ø§Ù„ÙØ±Ø¹ÙŠØ© Ù…Ø³ØªÙˆÙ‰ 2:",
        "final_summary": "Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ:",
        "compare_responses": "Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª:",
        "initial_response": "Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ©:",
        "final_response": "Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ù…Ø¹Ø¯Ù„Ø©:",
        "summary_details": "ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…Ù„Ø®Øµ:",
        "generate_final_summary": "Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ"
    },
    "Ğ ÑƒÑÑĞºĞ¸Ğ¹": {
        "enter_question": "Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ:",
        "initial_response": "ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚ ÑĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½:",
        "main_question": "ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ:",
        "response": "ĞÑ‚Ğ²ĞµÑ‚:",
        "your_response": "Ğ’Ğ°Ñˆ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ:",
        "validate_response": "ĞŸĞ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ´Ğ¸Ñ‚ÑŒ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚",
        "sub_questions_1": "ĞŸĞ¾Ğ´Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ 1:",
        "sub_questions_2": "ĞŸĞ¾Ğ´-Ğ¿Ğ¾Ğ´Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ 2:",
        "final_summary": "Ğ˜Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ğµ Ñ€ĞµĞ·ÑĞ¼Ğµ:",
        "compare_responses": "Ğ¡Ñ€Ğ°Ğ²Ğ½Ğ¸Ñ‚ÑŒ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹:",
        "initial_response": "ĞŸĞµÑ€Ğ²Ğ¾Ğ½Ğ°Ñ‡Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚:",
        "final_response": "ĞŸĞµÑ€ĞµÑ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚:",
        "summary_details": "Ğ”ĞµÑ‚Ğ°Ğ»Ğ¸ Ñ€ĞµĞ·ÑĞ¼Ğµ:",
        "generate_final_summary": "Ğ¡Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¸Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ğµ Ñ€ĞµĞ·ÑĞ¼Ğµ"
    },
    "à¤¹à¤¿à¤¨à¥à¤¦à¥€": {
        "enter_question": "à¤à¤• à¤®à¥à¤–à¥à¤¯ à¤¸à¤µà¤¾à¤² à¤¦à¤°à¥à¤œ à¤•à¤°à¥‡à¤‚:",
        "initial_response": "à¤ªà¥‚à¤°à¤¾ à¤‰à¤¤à¥à¤¤à¤° à¤‰à¤¤à¥à¤ªà¤¨à¥à¤¨:",
        "main_question": "à¤®à¥à¤–à¥à¤¯ à¤¸à¤µà¤¾à¤²:",
        "response": "à¤‰à¤¤à¥à¤¤à¤°:",
        "your_response": "à¤†à¤ªà¤•à¤¾ à¤®à¥à¤–à¥à¤¯ à¤¸à¤µà¤¾à¤² à¤•à¤¾ à¤‰à¤¤à¥à¤¤à¤°:",
        "validate_response": "à¤®à¥à¤–à¥à¤¯ à¤‰à¤¤à¥à¤¤à¤° à¤•à¥€ à¤ªà¥à¤·à¥à¤Ÿà¤¿ à¤•à¤°à¥‡à¤‚",
        "sub_questions_1": "à¤‰à¤ª-à¤¸à¤µà¤¾à¤² à¤¸à¥à¤¤à¤° 1:",
        "sub_questions_2": "à¤‰à¤ª-à¤‰à¤ª-à¤¸à¤µà¤¾à¤² à¤¸à¥à¤¤à¤° 2:",
        "final_summary": "à¤…à¤‚à¤¤à¤¿à¤® à¤¸à¤¾à¤°à¤¾à¤‚à¤¶:",
        "compare_responses": "à¤‰à¤¤à¥à¤¤à¤°à¥‹à¤‚ à¤•à¥€ à¤¤à¥à¤²à¤¨à¤¾ à¤•à¤°à¥‡à¤‚:",
        "initial_response": "à¤ªà¥à¤°à¤¾à¤°à¤‚à¤­à¤¿à¤• à¤‰à¤¤à¥à¤¤à¤°:",
        "final_response": "à¤ªà¥à¤¨à¤°à¥à¤µà¥à¤¯à¤µà¤¸à¥à¤¥à¤¿à¤¤ à¤‰à¤¤à¥à¤¤à¤°:",
        "summary_details": "à¤¸à¤¾à¤°à¤¾à¤‚à¤¶ à¤µà¤¿à¤µà¤°à¤£:",
        "generate_final_summary": "à¤…à¤‚à¤¤à¤¿à¤® à¤¸à¤¾à¤°à¤¾à¤‚à¤¶ à¤‰à¤¤à¥à¤ªà¤¨à¥à¤¨ à¤•à¤°à¥‡à¤‚"
    },
    "Deutsch": {
        "enter_question": "Geben Sie eine Hauptfrage ein:",
        "initial_response": "VollstÃ¤ndige Antwort generiert:",
        "main_question": "Hauptfrage:",
        "response": "Antwort:",
        "your_response": "Ihre Antwort auf die Hauptfrage:",
        "validate_response": "Hauptantwort Ã¼berprÃ¼fen",
        "sub_questions_1": "Unterfragen Ebene 1:",
        "sub_questions_2": "Unter-Unterfragen Ebene 2:",
        "final_summary": "Endzusammenfassung:",
        "compare_responses": "Antworten vergleichen:",
        "initial_response": "Erste Antwort:",
        "final_response": "Umformulierte Antwort:",
        "summary_details": "Zusammenfassungsdetails:",
        "generate_final_summary": "Endzusammenfassung generieren"
    },
    "æ—¥æœ¬èª": {
        "enter_question": "ä¸»è¦ãªè³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:",
        "initial_response": "å®Œå…¨ãªå¿œç­”ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸ:",
        "main_question": "ä¸»è¦ãªè³ªå•:",
        "response": "å¿œç­”:",
        "your_response": "ä¸»è¦ãªè³ªå•ã¸ã®ã‚ãªãŸã®å¿œç­”:",
        "validate_response": "ä¸»è¦ãªå¿œç­”ã‚’æ¤œè¨¼ã™ã‚‹",
        "sub_questions_1": "ã‚µãƒ–è³ªå•ãƒ¬ãƒ™ãƒ«1:",
        "sub_questions_2": "ã‚µãƒ–ã‚µãƒ–è³ªå•ãƒ¬ãƒ™ãƒ«2:",
        "final_summary": "æœ€çµ‚çš„ãªè¦ç´„:",
        "compare_responses": "å¿œç­”ã‚’æ¯”è¼ƒã™ã‚‹:",
        "initial_response": "åˆæœŸå¿œç­”:",
        "final_response": "æ”¹è¨‚ã•ã‚ŒãŸå¿œç­”:",
        "summary_details": "è¦ç´„ã®è©³ç´°:",
        "generate_final_summary": "æœ€çµ‚çš„ãªè¦ç´„ã‚’ç”Ÿæˆã™ã‚‹"
    }
}

# Ã‰tape 1 : Saisie de la question principale
st.write(f"### {translations[selected_language]['enter_question']}")
question = st.text_input("", placeholder="Comment vendre des bijoux sur internet ?")

if question:
    with st.spinner('ğŸ§  GÃ©nÃ©ration de la rÃ©ponse initiale...'):
        # GÃ©nÃ©rer la rÃ©ponse initiale avec l'API Hugging Face en utilisant la question entrÃ©e par l'utilisateur
        prompt_principal = f"""
        Question principale :
        "{question}"
        RÃ©ponds Ã  cette question principale avec une rÃ©ponse dÃ©taillÃ©e et longue. Explique chaque aspect en profondeur.
        Ensuite, gÃ©nÃ¨re deux sous-questions (nommÃ©es 1.1 et 1.2) qui approfondissent des aspects spÃ©cifiques de la question principale, puis rÃ©ponds Ã  chacune des deux sous-questions.
        Pour chaque sous-question de niveau 1 (1.1 et 1.2), gÃ©nÃ¨re deux nouvelles sous-questions (nommÃ©es 1.1.1, 1.1.2, 1.2.1, et 1.2.2) qui explorent davantage les rÃ©ponses, mais **ne gÃ©nÃ¨re pas de sous-questions supplÃ©mentaires** au-delÃ  de celles-ci. Limite-toi uniquement Ã  ces sous-questions.
        Format attendu :
        Question principale : [Question principale]
        RÃ©ponse : [RÃ©ponse principale]
        Sous-questions de Niveau 1 :
        1.1 [PremiÃ¨re sous-question]
        RÃ©ponse : [RÃ©ponse Ã  la sous-question 1.1]
        Sous-questions de Niveau 2 :
        1.1.1 [Sous-question dÃ©rivÃ©e de 1.1]
        RÃ©ponse : [RÃ©ponse Ã  la sous-question 1.1.1]
        1.1.2 [Sous-question dÃ©rivÃ©e de 1.1]
        RÃ©ponse : [RÃ©ponse Ã  la sous-question 1.1.2]
        1.2 [DeuxiÃ¨me sous-question]
        RÃ©ponse : [RÃ©ponse Ã  la sous-question 1.2]
        Sous-questions de Niveau 2 :
        1.2.1 [Sous-question dÃ©rivÃ©e de 1.2]
        RÃ©ponse : [RÃ©ponse Ã  la sous-question 1.2.1]
        1.2.2 [Sous-question dÃ©rivÃ©e de 1.2]
        RÃ©ponse : [RÃ©ponse Ã  la sous-question 1.2.2]
        
        stop toi a ce nombre de sous questions
        """
        logging.debug(f"Prompt gÃ©nÃ©rÃ© : {prompt_principal}")

        # Demande de rÃ©ponse Ã  l'API sans streaming
        response = client.chat_completion(
            model="mistralai/Mistral-7B-Instruct-v0.3",
            messages=[{"role": "user", "content": prompt_principal}],
            max_tokens=6000
        )

        # VÃ©rifier si la rÃ©ponse est vide
        if not response:
            st.error("âŒ Aucune rÃ©ponse n'a Ã©tÃ© reÃ§ue de l'API.")
        else:
            # Extraire la rÃ©ponse textuelle
            generated_response = response['choices'][0]['message']['content']
            st.write("### " + translations[selected_language]['initial_response'])
            st.write(f"**{translations[selected_language]['main_question']}** {question}")
            main_question_response = generated_response.split('Sous-questions de Niveau 1 :')[0].strip()
            st.write(f"**{translations[selected_language]['response']}** {main_question_response}")

            # Champ pour la rÃ©ponse de l'utilisateur Ã  la question principale
            st.subheader("ğŸ’¡ " + translations[selected_language]['your_response'])
            user_main_response = st.text_area(f"{translations[selected_language]['your_response']} {question}", placeholder="Entrez votre rÃ©ponse ici...")

            # EXTRACTION des sous-questions gÃ©nÃ©rÃ©es dynamiquement Ã  partir de la rÃ©ponse de l'IA
            sous_questions = re.findall(r'(\d+\.\d+(?:\.\d+)? [^\n]+)', generated_response)
            ia_responses = re.findall(r'RÃ©ponse : ([^\n]+)', generated_response)  # Extraire les rÃ©ponses IA aprÃ¨s "RÃ©ponse :"

            # VÃ©rifier que le nombre de sous-questions correspond au nombre de rÃ©ponses IA
            if len(sous_questions) != len(ia_responses):
                st.warning(f"âš ï¸ Nombre de sous-questions ({len(sous_questions)}) ne correspond pas au nombre de rÃ©ponses IA ({len(ia_responses)}).")

            # VÃ©rifier si des sous-questions sont bien extraites
            if sous_questions:
                st.write("### " + translations[selected_language]['sub_questions_1'])
                for sq in sous_questions:
                    st.write(f"ğŸ“Œ {sq}")
            else:
                st.error("âŒ Aucune sous-question n'a Ã©tÃ© extraite.")

            # CrÃ©er un formulaire pour que l'utilisateur puisse entrer ses rÃ©ponses aux mÃªmes sous-questions
            st.subheader("ğŸ’¡ Vos rÃ©ponses aux questions gÃ©nÃ©rÃ©es par l'IA")

            user_responses = {}
            response_sources = {}

            for idx, question in enumerate(sous_questions):
                question_id, question_text = question.split(' ', 1)

                # Carte pour chaque question
                with st.expander(f"**{question_id} : {question_text.strip()}**", expanded=True):
                    # Afficher la rÃ©ponse de l'IA uniquement si elle existe
                    if idx < len(ia_responses):
                        st.write(f"**{translations[selected_language]['response']}** {ia_responses[idx]}")
                    else:
                        st.write(f"**{translations[selected_language]['response']}** Aucune rÃ©ponse disponible.")

                    # Champ pour la rÃ©ponse de l'utilisateur avec une clÃ© unique
                    user_responses[question_id] = st.text_area(f"Votre rÃ©ponse pour {question_id}", placeholder="Entrez votre rÃ©ponse ici...", key=f"user_response_{question_id}")

                    # Niveau 1 : Choisir la catÃ©gorie gÃ©nÃ©rale
                    response_type = st.selectbox(f"Type d'origine de la rÃ©ponse pour {question_id}",
                                                 ["RÃ©ponse personnelle", "IA", "Forum", "RÃ©seaux sociaux",
                                                  "VidÃ©os en ligne", "Wikipedia", "Livre",
                                                  "Article scientifique", "Autre"],
                                                 key=f"type_{question_id}")

                    # Niveau 2 : Sous-choix en fonction du type sÃ©lectionnÃ©
                    if response_type == "RÃ©ponse personnelle":
                        origin_details = "RÃ©ponse fournie personnellement par l'utilisateur."

                    elif response_type == "IA":
                        ia_name = st.selectbox(f"Nom de l'IA pour {question_id}",
                                               ["ChatGPT", "Mistral", "Anthropic", "Bard", "Autre"],
                                               key=f"ia_{question_id}")
                        if ia_name == "Autre":
                            ia_name = st.text_input(f"PrÃ©cisez le nom de l'IA pour {question_id}", key=f"ia_custom_{question_id}")

                        ia_model = st.selectbox(f"ModÃ¨le de l'IA pour {question_id}",
                                                ["GPT-3.5", "GPT-4", "Mistral-7B", "Claude 2", "Autre"],
                                                key=f"model_{question_id}")
                        if ia_model == "Autre":
                            ia_model = st.text_input(f"PrÃ©cisez le modÃ¨le de l'IA pour {question_id}", key=f"model_custom_{question_id}")
                        origin_details = f"{ia_name}, modÃ¨le {ia_model}"

                    elif response_type == "Forum":
                        forum_name = st.selectbox(f"Nom du forum pour {question_id}",
                                                  ["Reddit", "Quora", "Stack Overflow", "Autre"],
                                                  key=f"forum_{question_id}")
                        if forum_name == "Autre":
                            forum_name = st.text_input(f"PrÃ©cisez le nom du forum pour {question_id}", key=f"forum_custom_{question_id}")
                        forum_link = st.text_input(f"Lien vers la discussion du forum pour {question_id}", key=f"forum_link_{question_id}")
                        origin_details = f"Forum : {forum_name}, Lien : {forum_link}"

                    elif response_type == "RÃ©seaux sociaux":
                        social_media = st.selectbox(f"Plateforme de rÃ©seaux sociaux pour {question_id}",
                                                    ["Twitter/X", "Facebook", "LinkedIn", "Instagram", "Autre"],
                                                    key=f"social_{question_id}")
                        if social_media == "Autre":
                            social_media = st.text_input(f"PrÃ©cisez la plateforme pour {question_id}", key=f"social_custom_{question_id}")
                        social_link = st.text_input(f"Lien vers le post pour {question_id}", key=f"social_link_{question_id}")
                        origin_details = f"RÃ©seau social : {social_media}, Lien : {social_link}"

                    elif response_type == "VidÃ©os en ligne":
                        video_platform = st.selectbox(f"Plateforme vidÃ©o pour {question_id}",
                                                      ["YouTube", "Vimeo", "TikTok", "Autre"],
                                                      key=f"video_{question_id}")
                        if video_platform == "Autre":
                            video_platform = st.text_input(f"PrÃ©cisez la plateforme vidÃ©o pour {question_id}", key=f"video_custom_{question_id}")
                        video_link = st.text_input(f"Lien vers la vidÃ©o pour {question_id}", key=f"video_link_{question_id}")
                        origin_details = f"VidÃ©o : {video_platform}, Lien : {video_link}"

                    elif response_type == "Wikipedia":
                        wiki_link = st.text_input(f"Lien vers l'article Wikipedia pour {question_id}", key=f"wiki_link_{question_id}")
                        origin_details = f"Wikipedia : {wiki_link}"

                    elif response_type == "Livre":
                        book_title = st.text_input(f"Titre du livre pour {question_id}", key=f"book_{question_id}")
                        book_author = st.text_input(f"Auteur du livre pour {question_id}", key=f"author_{question_id}")
                        origin_details = f"Livre : {book_title}, Auteur : {book_author}"

                    elif response_type == "Article scientifique":
                        article_title = st.text_input(f"Titre de l'article pour {question_id}", key=f"article_{question_id}")
                        journal_name = st.text_input(f"Nom du journal ou de la publication pour {question_id}", key=f"journal_{question_id}")
                        article_link = st.text_input(f"Lien ou DOI pour {question_id}", key=f"article_link_{question_id}")
                        origin_details = f"Article : {article_title}, Journal : {journal_name}, Lien/DOI : {article_link}"

                    else:  # Autre
                        origin_details = st.text_input(f"PrÃ©cisez l'origine de la rÃ©ponse pour {question_id}", key=f"other_{question_id}")

                    # Sauvegarder l'origine et les dÃ©tails
                    response_sources[question_id] = {"type": response_type, "details": origin_details}

            # Si l'utilisateur a fourni des rÃ©ponses, les afficher avec leur origine
            if st.button("âœ… Envoyer vos rÃ©ponses"):
                st.subheader("ğŸ” Vos rÃ©ponses soumises :")
                if user_main_response:
                    st.write(f"**Question principale :** {user_main_response}")
                else:
                    st.write(f"**Question principale :** Aucune rÃ©ponse soumise.")

                for question_id in user_responses:
                    user_answer = user_responses[question_id]
                    if user_answer:
                        st.write(f"**{question_id} :** {user_answer}")
                        source_info = response_sources[question_id]
                        st.write(f"Origine de votre rÃ©ponse : {source_info['type']}")
                        if source_info['details']:
                            st.write(f"DÃ©tails supplÃ©mentaires : {source_info['details']}")
                    else:
                        st.write(f"**{question_id} :** Aucune rÃ©ponse soumise.")

    # Ã‰tape 4 : Reformulation finale
    if st.button(translations[selected_language]['generate_final_summary']):
        with st.spinner('ğŸ“ GÃ©nÃ©ration de la reformulation finale...'):
            reformulation_prompt = f"Question principale : \"{question}\"\n\nRÃ©ponse initiale :\n{main_question_response}\n\n"
            reformulation_prompt += "Voici la rÃ©ponse initiale Ã  la question principale :\n"
            reformulation_prompt += f"{main_question_response}\n\n"
            reformulation_prompt += "Analyse des sous-questions et des rÃ©ponses IA et utilisateur :\n\n"

            # Boucle sur les sous-questions et leurs rÃ©ponses IA/utilisateur
            for question_id, ia_response in zip(sous_questions, ia_responses):
                user_response = user_responses.get(question_id, "Pas de rÃ©ponse utilisateur")
                reformulation_prompt += f"Sous-question : {question_id}\n"
                reformulation_prompt += f"RÃ©ponse IA : {ia_response}\n"
                reformulation_prompt += f"RÃ©ponse utilisateur : {user_response}\n\n"

            # Ajout d'un rappel explicite pour reformuler la rÃ©ponse principale en dÃ©tail
            reformulation_prompt += (
                "\nReformule la rÃ©ponse Ã  la **question principale** en prenant en compte "
                "les informations des sous-questions et des rÃ©ponses utilisateur et IA. "
                "La reformulation doit Ãªtre longue, dÃ©taillÃ©e et rÃ©pondre spÃ©cifiquement "
                "Ã  la question principale tout en intÃ©grant des informations pertinentes des "
                "sous-questions. Assure-toi que toutes les rÃ©ponses des sous-questions "
                "soient utilisÃ©es pour enrichir la rÃ©ponse."
            )

            logging.debug(f"Prompt pour reformulation finale : {reformulation_prompt}")

            reformulation_response = client.chat_completion(
                model="mistralai/Mistral-7B-Instruct-v0.3",
                messages=[{"role": "user", "content": reformulation_prompt}],
                max_tokens=6000
            )

            if reformulation_response:
                final_summary = reformulation_response['choices'][0]['message']['content']
                st.write(f"### {translations[selected_language]['final_summary']}")
                st.write(final_summary)

                # Comparaison des rÃ©ponses
                st.write(f"### {translations[selected_language]['compare_responses']}")
                st.write(f"**{translations[selected_language]['initial_response']}**")
                st.write(main_question_response)
                st.write(f"**{translations[selected_language]['final_response']}**")
                st.write(final_summary)

                st.write(f"### {translations[selected_language]['summary_details']}")
                st.write("La reformulation a pris en compte les rÃ©ponses IA et utilisateur pour chaque sous-question. Voici un rÃ©sumÃ© des Ã©lÃ©ments ajoutÃ©s ou modifiÃ©s :")

                for question_id, response in zip(sous_questions, ia_responses):
                    user_response = user_responses.get(question_id, "")
                    st.write(f"- **{question_id}** : RÃ©ponse IA : {response}, RÃ©ponse utilisateur : {user_response}")

            else:
                st.error("âŒ Aucune reformulation finale n'a Ã©tÃ© reÃ§ue de l'API aprÃ¨s plusieurs tentatives.")
