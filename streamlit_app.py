import streamlit as st
import logging
from huggingface_hub import InferenceClient
import re

# Configuration du logger
logging.basicConfig(level=logging.DEBUG)

# RÃ©cupÃ©ration de la clÃ© API Hugging Face depuis les secrets de Streamlit
api_key = st.secrets["HUGGINGFACE_API_KEY"]

# Initialisation du client Hugging Face avec la clÃ© API rÃ©cupÃ©rÃ©e
client = InferenceClient(api_key=api_key)

# Interface Streamlit
st.title("ğŸ§ Explorateur de Sous-questions avec IA")



# SÃ©lecteur de langue
languages = {
    "English": "en",
    "FranÃ§ais": "fr",
    "EspaÃ±ol": "es",
    "PortuguÃªs": "pt",
    "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©": "ar",
    "Ğ ÑƒÑÑĞºĞ¸Ğ¹": "ru",
    "à¤¹à¤¿à¤¨à¥à¤¦à¥€": "hi",
    "Deutsch": "de",
    "æ—¥æœ¬èª": "ja"
}
selected_language = st.selectbox("SÃ©lectionnez la langue", list(languages.keys()))

# Textes fixes traduits
translations = {
    "English": {
        "enter_question": "Enter a main question:",
        "initial_response": "Complete response generated:",
        "main_question": "Main question:",
        "response": "Response:",
        "your_response": "Your response to the main question:",
        "validate_response": "Validate main response",
        "sub_questions_1": "Sub-questions Level 1:",
        "sub_questions_2": "Sub-sub-questions Level 2:",
        "final_summary": "Final summary:",
        "compare_responses": "Compare responses:",
        "initial_response": "Initial response:",
        "final_response": "Final response:",
        "summary_details": "Summary details:",
        "generate_final_summary": "Generate final summary"
    },
    "FranÃ§ais": {
        "enter_question": "Entrez une question principale :",
        "initial_response": "RÃ©ponse complÃ¨te gÃ©nÃ©rÃ©e :",
        "main_question": "Question principale :",
        "response": "RÃ©ponse :",
        "your_response": "Votre rÃ©ponse Ã  la question principale :",
        "validate_response": "Valider la rÃ©ponse principale",
        "sub_questions_1": "Sous-questions de Niveau 1 :",
        "sub_questions_2": "Sous-sous-questions de Niveau 2 :",
        "final_summary": "Reformulation finale :",
        "compare_responses": "Comparaison des rÃ©ponses :",
        "initial_response": "RÃ©ponse initiale :",
        "final_response": "RÃ©ponse reformulÃ©e :",
        "summary_details": "DÃ©tails des Ã©tapes de reformulation :",
        "generate_final_summary": "GÃ©nÃ©rer la reformulation finale"
    },
    "EspaÃ±ol": {
        "enter_question": "Introduce una pregunta principal:",
        "initial_response": "Respuesta completa generada:",
        "main_question": "Pregunta principal:",
        "response": "Respuesta:",
        "your_response": "Tu respuesta a la pregunta principal:",
        "validate_response": "Validar respuesta principal",
        "sub_questions_1": "Subpreguntas de Nivel 1:",
        "sub_questions_2": "Sub-subpreguntas de Nivel 2:",
        "final_summary": "Resumen final:",
        "compare_responses": "Comparar respuestas:",
        "initial_response": "Respuesta inicial:",
        "final_response": "Respuesta reformulada:",
        "summary_details": "Detalles del resumen:",
        "generate_final_summary": "Generar resumen final"
    },
    "PortuguÃªs": {
        "enter_question": "Insira uma pergunta principal:",
        "initial_response": "Resposta completa gerada:",
        "main_question": "Pergunta principal:",
        "response": "Resposta:",
        "your_response": "Sua resposta Ã  pergunta principal:",
        "validate_response": "Validar resposta principal",
        "sub_questions_1": "Subperguntas de NÃ­vel 1:",
        "sub_questions_2": "Sub-subperguntas de NÃ­vel 2:",
        "final_summary": "Resumo final:",
        "compare_responses": "Comparar respostas:",
        "initial_response": "Resposta inicial:",
        "final_response": "Resposta reformulada:",
        "summary_details": "Detalhes do resumo:",
        "generate_final_summary": "Gerar resumo final"
    },
    "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©": {
        "enter_question": "Ø£Ø¯Ø®Ù„ Ø³Ø¤Ø§Ù„Ø§Ù‹ Ø±Ø¦ÙŠØ³ÙŠØ§Ù‹:",
        "initial_response": "Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø© Ø§Ù„Ù…ÙˆÙ„Ø¯Ø©:",
        "main_question": "Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ:",
        "response": "Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:",
        "your_response": "Ø¥Ø¬Ø§Ø¨ØªÙƒ Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ:",
        "validate_response": "ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©",
        "sub_questions_1": "Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ÙØ±Ø¹ÙŠØ© Ù…Ø³ØªÙˆÙ‰ 1:",
        "sub_questions_2": "Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ÙØ±Ø¹ÙŠØ© Ø§Ù„ÙØ±Ø¹ÙŠØ© Ù…Ø³ØªÙˆÙ‰ 2:",
        "final_summary": "Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ:",
        "compare_responses": "Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª:",
        "initial_response": "Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ©:",
        "final_response": "Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ù…Ø¹Ø¯Ù„Ø©:",
        "summary_details": "ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…Ù„Ø®Øµ:",
        "generate_final_summary": "Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ"
    },
    "Ğ ÑƒÑÑĞºĞ¸Ğ¹": {
        "enter_question": "Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ:",
        "initial_response": "ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚ ÑĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½:",
        "main_question": "ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ:",
        "response": "ĞÑ‚Ğ²ĞµÑ‚:",
        "your_response": "Ğ’Ğ°Ñˆ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ:",
        "validate_response": "ĞŸĞ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ´Ğ¸Ñ‚ÑŒ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚",
        "sub_questions_1": "ĞŸĞ¾Ğ´Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ 1:",
        "sub_questions_2": "ĞŸĞ¾Ğ´-Ğ¿Ğ¾Ğ´Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ 2:",
        "final_summary": "Ğ˜Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ğµ Ñ€ĞµĞ·ÑĞ¼Ğµ:",
        "compare_responses": "Ğ¡Ñ€Ğ°Ğ²Ğ½Ğ¸Ñ‚ÑŒ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹:",
        "initial_response": "ĞŸĞµÑ€Ğ²Ğ¾Ğ½Ğ°Ñ‡Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚:",
        "final_response": "ĞŸĞµÑ€ĞµÑ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚:",
        "summary_details": "Ğ”ĞµÑ‚Ğ°Ğ»Ğ¸ Ñ€ĞµĞ·ÑĞ¼Ğµ:",
        "generate_final_summary": "Ğ¡Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¸Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ğµ Ñ€ĞµĞ·ÑĞ¼Ğµ"
    },
    "à¤¹à¤¿à¤¨à¥à¤¦à¥€": {
        "enter_question": "à¤à¤• à¤®à¥à¤–à¥à¤¯ à¤¸à¤µà¤¾à¤² à¤¦à¤°à¥à¤œ à¤•à¤°à¥‡à¤‚:",
        "initial_response": "à¤ªà¥‚à¤°à¤¾ à¤‰à¤¤à¥à¤¤à¤° à¤‰à¤¤à¥à¤ªà¤¨à¥à¤¨:",
        "main_question": "à¤®à¥à¤–à¥à¤¯ à¤¸à¤µà¤¾à¤²:",
        "response": "à¤‰à¤¤à¥à¤¤à¤°:",
        "your_response": "à¤†à¤ªà¤•à¤¾ à¤®à¥à¤–à¥à¤¯ à¤¸à¤µà¤¾à¤² à¤•à¤¾ à¤‰à¤¤à¥à¤¤à¤°:",
        "validate_response": "à¤®à¥à¤–à¥à¤¯ à¤‰à¤¤à¥à¤¤à¤° à¤•à¥€ à¤ªà¥à¤·à¥à¤Ÿà¤¿ à¤•à¤°à¥‡à¤‚",
        "sub_questions_1": "à¤‰à¤ª-à¤¸à¤µà¤¾à¤² à¤¸à¥à¤¤à¤° 1:",
        "sub_questions_2": "à¤‰à¤ª-à¤‰à¤ª-à¤¸à¤µà¤¾à¤² à¤¸à¥à¤¤à¤° 2:",
        "final_summary": "à¤…à¤‚à¤¤à¤¿à¤® à¤¸à¤¾à¤°à¤¾à¤‚à¤¶:",
        "compare_responses": "à¤‰à¤¤à¥à¤¤à¤°à¥‹à¤‚ à¤•à¥€ à¤¤à¥à¤²à¤¨à¤¾ à¤•à¤°à¥‡à¤‚:",
        "initial_response": "à¤ªà¥à¤°à¤¾à¤°à¤‚à¤­à¤¿à¤• à¤‰à¤¤à¥à¤¤à¤°:",
        "final_response": "à¤ªà¥à¤¨à¤°à¥à¤µà¥à¤¯à¤µà¤¸à¥à¤¥à¤¿à¤¤ à¤‰à¤¤à¥à¤¤à¤°:",
        "summary_details": "à¤¸à¤¾à¤°à¤¾à¤‚à¤¶ à¤µà¤¿à¤µà¤°à¤£:",
        "generate_final_summary": "à¤…à¤‚à¤¤à¤¿à¤® à¤¸à¤¾à¤°à¤¾à¤‚à¤¶ à¤‰à¤¤à¥à¤ªà¤¨à¥à¤¨ à¤•à¤°à¥‡à¤‚"
    },
    "Deutsch": {
        "enter_question": "Geben Sie eine Hauptfrage ein:",
        "initial_response": "VollstÃ¤ndige Antwort generiert:",
        "main_question": "Hauptfrage:",
        "response": "Antwort:",
        "your_response": "Ihre Antwort auf die Hauptfrage:",
        "validate_response": "Hauptantwort Ã¼berprÃ¼fen",
        "sub_questions_1": "Unterfragen Ebene 1:",
        "sub_questions_2": "Unter-Unterfragen Ebene 2:",
        "final_summary": "Endzusammenfassung:",
        "compare_responses": "Antworten vergleichen:",
        "initial_response": "Erste Antwort:",
        "final_response": "Umformulierte Antwort:",
        "summary_details": "Zusammenfassungsdetails:",
        "generate_final_summary": "Endzusammenfassung generieren"
    },
    "æ—¥æœ¬èª": {
        "enter_question": "ä¸»è¦ãªè³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:",
        "initial_response": "å®Œå…¨ãªå¿œç­”ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸ:",
        "main_question": "ä¸»è¦ãªè³ªå•:",
        "response": "å¿œç­”:",
        "your_response": "ä¸»è¦ãªè³ªå•ã¸ã®ã‚ãªãŸã®å¿œç­”:",
        "validate_response": "ä¸»è¦ãªå¿œç­”ã‚’æ¤œè¨¼ã™ã‚‹",
        "sub_questions_1": "ã‚µãƒ–è³ªå•ãƒ¬ãƒ™ãƒ«1:",
        "sub_questions_2": "ã‚µãƒ–ã‚µãƒ–è³ªå•ãƒ¬ãƒ™ãƒ«2:",
        "final_summary": "æœ€çµ‚çš„ãªè¦ç´„:",
        "compare_responses": "å¿œç­”ã‚’æ¯”è¼ƒã™ã‚‹:",
        "initial_response": "åˆæœŸå¿œç­”:",
        "final_response": "æ”¹è¨‚ã•ã‚ŒãŸå¿œç­”:",
        "summary_details": "è¦ç´„ã®è©³ç´°:",
        "generate_final_summary": "æœ€çµ‚çš„ãªè¦ç´„ã‚’ç”Ÿæˆã™ã‚‹"
    }
}

# Ã‰tape 1 : Saisie de la question principale
st.write(f"### {translations[selected_language]['enter_question']}")
question = st.text_input("", placeholder="Comment vendre des bijoux sur internet ?", label_visibility="collapsed")

if question:
    with st.spinner('ğŸ§  GÃ©nÃ©ration de la rÃ©ponse initiale...'):
        # PrÃ©paration du prompt principal
        prompt_principal = f"""
        Question principale : "{question}"

        RÃ©ponds Ã  cette question principale avec une rÃ©ponse dÃ©taillÃ©e et longue. Explique chaque aspect en profondeur.
        
        Ensuite, gÃ©nÃ¨re deux sous-questions (nommÃ©es 1.1 et 1.2) qui approfondissent des aspects spÃ©cifiques de la question principale, puis rÃ©ponds Ã  chacune des deux sous-questions.
        
        Pour chaque sous-question de niveau 1 (1.1 et 1.2), gÃ©nÃ¨re deux nouvelles sous-questions (nommÃ©es 1.1.1, 1.1.2, 1.2.1, et 1.2.2) qui explorent davantage les rÃ©ponses, mais **ne gÃ©nÃ¨re pas de sous-questions supplÃ©mentaires** au-delÃ  de celles-ci. Limite-toi uniquement Ã  ces sous-questions.
        
        Format attendu :
        Question principale : [Question principale]
        
        RÃ©ponse : [RÃ©ponse principale]
        Sous-questions de Niveau 1 :
        
        1.1 [PremiÃ¨re sous-question]
        RÃ©ponse : [RÃ©ponse Ã  la sous-question 1.1]
        
        Sous-questions de Niveau 2 :
        1.1.1 [Sous-question dÃ©rivÃ©e de 1.1]
        RÃ©ponse : [RÃ©ponse Ã  la sous-question 1.1.1]
        1.1.2 [Sous-question dÃ©rivÃ©e de 1.1]
        RÃ©ponse : [RÃ©ponse Ã  la sous-question 1.1.2]
        
        1.2 [DeuxiÃ¨me sous-question]
        RÃ©ponse : [RÃ©ponse Ã  la sous-question 1.2]
        
        Sous-questions de Niveau 2 :
        1.2.1 [Sous-question dÃ©rivÃ©e de 1.2]
        RÃ©ponse : [RÃ©ponse Ã  la sous-question 1.2.1]
        1.2.2 [Sous-question dÃ©rivÃ©e de 1.2]
        RÃ©ponse : [RÃ©ponse Ã  la sous-question 1.2.2]
        
        stop toi a ce nombre de sous questions
        """
        
        # Demande de rÃ©ponse Ã  l'API sans streaming
        response = client.chat_completion(
            model="mistralai/Mistral-7B-Instruct-v0.3",
            messages=[{"role": "user", "content": prompt_principal}],
            max_tokens=6000
        )

        # VÃ©rifier si la rÃ©ponse est vide
        if not response:
            st.error("âŒ Aucune rÃ©ponse n'a Ã©tÃ© reÃ§ue de l'API.")
        else:
            # Extraire la rÃ©ponse textuelle
            generated_response = response['choices'][0]['message']['content']
            st.write("### " + translations[selected_language]['initial_response'])
            st.write(f"**{translations[selected_language]['main_question']}** {question}")
            main_question_response = generated_response.split('Sous-questions de Niveau 1 :')[0].strip()
            st.write(f"**{translations[selected_language]['response']}** {main_question_response}")

            # Champ pour la rÃ©ponse de l'utilisateur Ã  la question principale
            st.subheader("ğŸ’¡ " + translations[selected_language]['your_response'])
            user_main_response = st.text_area(f"{translations[selected_language]['your_response']} {question}", placeholder="Entrez votre rÃ©ponse ici...")

            # EXTRACTION des sous-questions gÃ©nÃ©rÃ©es dynamiquement Ã  partir de la rÃ©ponse de l'IA
            sous_questions = re.findall(r'(\d+\.\d+(?:\.\d+)? [^\n]+)', generated_response)
            ia_responses = re.findall(r'RÃ©ponse : ([^\n]+)', generated_response)  # Extraire les rÃ©ponses IA aprÃ¨s "RÃ©ponse :"

            # VÃ©rifier que le nombre de sous-questions correspond au nombre de rÃ©ponses IA
            if len(sous_questions) != len(ia_responses):
                st.warning(f"âš ï¸ Nombre de sous-questions ({len(sous_questions)}) ne correspond pas au nombre de rÃ©ponses IA ({len(ia_responses)}).")

            # Affichage des sous-questions et des rÃ©ponses IA
            if sous_questions:
                st.write("### " + translations[selected_language]['sub_questions_1'])
                user_responses = {}
                response_sources = {}

                for idx, question in enumerate(sous_questions):
                    question_id, question_text = question.split(' ', 1)

                    # Carte pour chaque question
                    with st.expander(f"**{question_id} : {question_text.strip()}**", expanded=True):
                        # Afficher la rÃ©ponse de l'IA uniquement si elle existe
                        if idx < len(ia_responses):
                            st.write(f"**{translations[selected_language]['response']}** {ia_responses[idx]}")
                        else:
                            st.write(f"**{translations[selected_language]['response']}** Aucune rÃ©ponse disponible.")

                        # Champ pour la rÃ©ponse de l'utilisateur
                        user_responses[question_id] = st.text_area(f"Votre rÃ©ponse pour {question_id}", placeholder="Entrez votre rÃ©ponse ici...", key=f"user_response_{question_id}")

                        # Choix d'origine de la rÃ©ponse utilisateur
                        response_type = st.selectbox(f"Type d'origine de la rÃ©ponse pour {question_id}",
                                                     ["RÃ©ponse personnelle", "IA", "Forum", "RÃ©seaux sociaux",
                                                      "VidÃ©os en ligne", "Wikipedia", "Livre",
                                                      "Article scientifique", "Autre"],
                                                     key=f"type_{question_id}")
                        origin_details = ""
                        if response_type == "Autre":
                            origin_details = st.text_input(f"PrÃ©cisez l'origine de la rÃ©ponse pour {question_id}", key=f"other_{question_id}")
                        response_sources[question_id] = {"type": response_type, "details": origin_details}

                # Affichage de la reformulation finale
                if st.button(translations[selected_language]['final_summary']):
                    with st.spinner('ğŸ“ GÃ©nÃ©ration de la reformulation finale...'):
                        reformulation_prompt = f"Question principale : \"{question}\"\n\n"
                        reformulation_prompt += "Voici la rÃ©ponse initiale Ã  la question principale :\n"
                        reformulation_prompt += f"{main_question_response}\n\n"
                        reformulation_prompt += "Analyse des sous-questions et des rÃ©ponses IA et utilisateur :\n\n"

                        # Boucle sur les sous-questions et leurs rÃ©ponses IA/utilisateur
                        for question_id, ia_response in zip(sous_questions, ia_responses):
                            user_response = user_responses.get(question_id, "Pas de rÃ©ponse utilisateur")
                            reformulation_prompt += f"Sous-question : {question_id}\n"
                            reformulation_prompt += f"RÃ©ponse IA : {ia_response}\n"
                            reformulation_prompt += f"RÃ©ponse utilisateur : {user_response}\n\n"

                        # GÃ©nÃ©ration de la reformulation
                        reformulation_prompt += (
                            f"\nMaintenant, reformule la **rÃ©ponse Ã  la question principale** : \"{question}\" en prenant en compte "
                            "les informations des sous-questions et des rÃ©ponses IA et utilisateur."
                        )
                        reformulation_response = client.chat_completion(
                            model="mistralai/Mistral-7B-Instruct-v0.3",
                            messages=[{"role": "user", "content": reformulation_prompt}],
                            max_tokens=6000
                        )

                        if reformulation_response:
                            final_summary = reformulation_response['choices'][0]['message']['content']
                            st.write(f"### {translations[selected_language]['final_summary']}")
                            st.write(final_summary)
                        else:
                            st.error("âŒ Aucune reformulation finale n'a Ã©tÃ© reÃ§ue de l'API.")
            else:
                st.error("âŒ Aucune sous-question n'a Ã©tÃ© extraite.")
